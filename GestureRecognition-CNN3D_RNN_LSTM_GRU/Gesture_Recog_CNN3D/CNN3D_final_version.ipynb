{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c5dce3042216576b306da273c327fb1b0996bcc1",
    "colab_type": "text",
    "id": "BAW47NA4OoX3"
   },
   "source": [
    "# Gesture Recognition (Using Conv3D technique)\n",
    "\n",
    "*Author : Anugraha Sinha*\n",
    "\n",
    "*Email : anugraha[dot]sinha[at]gmail[dot]com*\n",
    "\n",
    "In this case, we will be using a CNN2D + GRU (Gated Recurrent Unit) Neural Network for evaluating geatures in videos. \n",
    "The data provided as following features\n",
    "1. 30 Video frames in each video\n",
    "2. Each frame - 3 Channel (RGB)\n",
    "3. 5 kinds of gestures (Up, Down, Right, Left, Stop)\n",
    "\n",
    "The objective is to be fullfilled for a hypothetical Smart TV company which is trying to incorporate geature recognition in its product where in the gestures mean following things\n",
    "\n",
    "Gesture   |       Left       |    Right    |    Stop      |    Down     |     Up\n",
    "----------| -----------------|-------------|--------------|-------------|-----------\n",
    "Objectives| Previous Channel | Next Channel| Stop Playing | Volume Down | Volume Up\n",
    "Y Value (Integer) | 0 | 1 | 2 | 3 | 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9976d04ccbabdd551630459c34e7f83737353e86",
    "colab_type": "text",
    "id": "BUE2GD52OoX4"
   },
   "source": [
    "##### Library imports #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T10:02:45.291268Z",
     "start_time": "2018-12-24T10:02:16.166997Z"
    },
    "_uuid": "f10fa45394d670436832273227e63a6802aa3b97",
    "colab": {},
    "colab_type": "code",
    "id": "Bml_XJfdOoX5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread, imresize\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "58ef5e05488d0590cff30e5492d0ef48260240eb",
    "colab_type": "text",
    "id": "dCpE2a3SOoX_"
   },
   "source": [
    "##### We set the random seed so that the results don't vary drastically.#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T10:03:12.325679Z",
     "start_time": "2018-12-24T10:02:45.295206Z"
    },
    "_uuid": "9a5d6b0bc1b6f0f69c9d92b3b14d03b29cc912c1",
    "colab": {},
    "colab_type": "code",
    "id": "2LDTVf4XOoYA",
    "outputId": "a7b7e406-64e2-4461-be5d-3fedd68652ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "186bcc4bcf062e2eb41ef6aff011f7e78c3dafbd",
    "colab_type": "text",
    "id": "F0ufz9YDOoYG"
   },
   "source": [
    "##### We set the train_doc and val_doc location #####\n",
    "*Note : Please set this location as per your environment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T10:03:12.439253Z",
     "start_time": "2018-12-24T10:03:12.328631Z"
    },
    "_uuid": "38a94b46245142b33adcbf5e5b6cedebf10b3343",
    "colab": {},
    "colab_type": "code",
    "id": "O0b3mGDYOoYH"
   },
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('../input/data/Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('../input/data/Project_data/val.csv').readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e626b62451dced61e305ce8ada14ce219f0838cb",
    "colab_type": "text",
    "id": "lWklhutGOoYK"
   },
   "source": [
    "#### Image Processor ####\n",
    "The objective of this function is:\n",
    "Resize the images as per *transform_size* given by user, or take it as (120,120)\n",
    "\n",
    "**Reason**\n",
    "\n",
    "In the training data we have 2 types of video, where video frame sizes are as *(360,360)* and *(160,120)* Therefore to keep things consistent, we build a image processor which perform cropping of the image.\n",
    "\n",
    "**Note**\n",
    "\n",
    "Cropping is done as a centered image, i.e., we take the center as the reference and crop the images from both sides. For (360,360) we can use skimage.transform.resize function. However, for *(160,120)* we will have to some manual processing to crop images by the center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T10:03:24.517873Z",
     "start_time": "2018-12-24T10:03:12.444250Z"
    },
    "_uuid": "86d8bd0f1a0ac9340795e7fe0f3da136fa7b2179",
    "colab": {},
    "colab_type": "code",
    "id": "CVuvI0wBOoYL"
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "def image_processor(orig_image,transform_size=(120,120)):\n",
    "    # If we have an image of (360,360,3) then we use resize function.\n",
    "    # If we have an image of \n",
    "    new_image = orig_image\n",
    "    if orig_image.shape == (360,360,3):\n",
    "        new_image = resize(orig_image,transform_size)\n",
    "    else:\n",
    "        start_row = (orig_image.shape[0] - transform_size[0])//2\n",
    "        end_row = start_row + transform_size[0]\n",
    "        \n",
    "        start_col = (orig_image.shape[1] - transform_size[1])//2\n",
    "        end_col = start_col + transform_size[1]\n",
    "        new_image = orig_image[start_row:end_row,start_col:end_col,:]\n",
    "    #new_image = resize(orig_image,transform_size)\n",
    "    return(new_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9321caffe1256f58b6d1de5b144616dcc1c54d98",
    "colab_type": "text",
    "id": "fJT7tooQOoYQ"
   },
   "source": [
    "#### Sequence Generator ####\n",
    "This function provides a list of frame sequences we would like to use training\n",
    "\n",
    "Arguments\n",
    "\n",
    "a) choiceoflist\n",
    "\n",
    "\n",
    "choicelist | 0 | 1 | 2\n",
    "-----------|---|---|---\n",
    "Return list type | range(0,30,1) | range(0,30,2) | [0,1,2,3,4,5,6,9,12,15,18,21,24,25,26,27,28,29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "80890b27f84019c7e4f69e7f6d325a3de4157fc3",
    "colab": {},
    "colab_type": "code",
    "id": "_OtmFDceOoYQ"
   },
   "outputs": [],
   "source": [
    "def getframeselectionlist(choiceoflist=0):\n",
    "    if choiceoflist==0:\n",
    "        return [frame for frame in range(0,30,1)] # Returns 100% of frames, number of frames=30\n",
    "    elif choiceoflist==1:\n",
    "        return [frame for frame in range(0,30,2)] # returns 50% of frames, number of frames=15\n",
    "    elif choiceoflist==2:\n",
    "        \n",
    "        # For this we are taking first 5 frame+skip frame sequence+last 5 frame of the sequence\n",
    "        \n",
    "        frame_sequence=[]\n",
    "        \n",
    "        startframesequence=[0,1,2,3,4,5]\n",
    "        endframesequence=[25,26,27,28,29]\n",
    "        skip_sequence=3  #\n",
    "        middleframesequnce=[k for k in range(6,25,skip_sequence)]\n",
    "        \n",
    "        frame_sequence.extend(startframesequence)\n",
    "        frame_sequence.extend(middleframesequnce)\n",
    "        frame_sequence.extend(endframesequence)\n",
    "        \n",
    "        return frame_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a34a0be6eed201b41dbf4ca2ac5747e20da095a9",
    "colab_type": "text",
    "id": "mXNn0v2NOoYV"
   },
   "source": [
    "### Generator ###\n",
    "This is heart of complete training process. It pumps batched data to network during learning and prediction both. The function description is given below\n",
    "\n",
    "**Arguments**\n",
    "\n",
    "1. Source Path - Directory path to be considered for reading video/images frames\n",
    "2. folder_list - Lines from the train_doc we read above.\n",
    "3. batch_size - The batch_size we want to select.\n",
    "4. transform_size - The image transformation size we  (Default - (120,120)\n",
    "5. frame_selection_list - frame_list obtained from frame_generator (Default - range(30))\n",
    "6. process_input_func - To be provided in case CNN2D+RNN type modelling being done\n",
    "7. base_model - To be provided in case CNN2D+RNN type modelling being done.\n",
    "\n",
    "**Working**\n",
    "* Case when CNN3D modelling being done\n",
    "\n",
    "In this case, for each batch (according to batch size), we build \n",
    "\n",
    "1. **batch_data** = *(batch_size, number_of_frames,image_size_x,image_size_y,n_channels)*\n",
    "2. We normalize each channel (RGB) by dividing the pixel value with 255.\n",
    "\n",
    "\n",
    "* Case when CNN2D+RNN modelling being done (RNN can be any of SimpleRNN/LSTM/GRU)\n",
    "\n",
    "In this case, for each batch (according to batch size), we build\n",
    "\n",
    "1. **batch_data** = *(batch_size, number_of_frames,image_size_x,image_size_y,n_channels)*\n",
    "2. reshape batch data as **batch_data.reshape(batch_size * number_of_frames , image_size_x , image_size_y , n_channels)**.\n",
    "3. Above reshaped numpy array is sent to *process_input_func* of the pre-learned CNN2D function. This will produce modified image vector as per pre-learned CNN2D function (like VGG19/VGG16/etc.)\n",
    "4. After *process_input_func* we reshape again to *(batch_size, number_of_frames, outputs from CNN2D vector)*\n",
    "\n",
    "\n",
    "* Final Output\n",
    "\n",
    "The final output of the function has a tuple which has the batch_data (processed) and one-hot-encoded Y variable.\n",
    "One-hot-encoded numpy array will be of size (batch_size, 5) since we have 5 kind of gestures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T10:03:24.551099Z",
     "start_time": "2018-12-24T10:03:24.517873Z"
    },
    "_uuid": "aa673970c0bfce98e8f250888079d7ad9612fcbb",
    "colab": {},
    "colab_type": "code",
    "id": "zfnxdzOWOoYV"
   },
   "outputs": [],
   "source": [
    "def generator(source_path,\n",
    "              folder_list,\n",
    "              batch_size,\n",
    "              transform_size = (120,120),\n",
    "              frame_selection_list = range(30),\n",
    "              process_input_func=None,\n",
    "              base_model = None):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = frame_selection_list\n",
    "    channels = 3\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = int(len(t) / batch_size) if len(t) % batch_size == 0 else (len(t) // batch_size)\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,len(frame_selection_list),transform_size[0],transform_size[1],channels)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                #print(t[folder + (batch*batch_size)].split(';')[0])\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float64)\n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    image = image_processor(image,transform_size)\n",
    "                    if base_model:\n",
    "                        # This is when we are using a pre-learned CNN2D network\n",
    "                        image = process_input_func(image)\n",
    "                        \n",
    "                    else:\n",
    "                        # This is when we are building a Conv3D network\n",
    "                        image = image/255\n",
    "\n",
    "                    batch_data[folder,idx,:,:,0] = image[:,:,0]\n",
    "                    batch_data[folder,idx,:,:,1] = image[:,:,1]\n",
    "                    batch_data[folder,idx,:,:,2] = image[:,:,2]\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            if base_model:\n",
    "                s1 = batch_data.shape\n",
    "                n1 = base_model.predict(batch_data.reshape(s1[0]*s1[1],s1[2],s1[3],s1[4]))\n",
    "                s2 = n1.shape\n",
    "                batch_data = n1.reshape(s1[0],s1[1],s2[1],s2[2],s2[3])\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "        # remaining data #\n",
    "        if len(t) % batch_size != 0:                                      # Execute only if, we need to\n",
    "            batch_data = np.zeros((len(t) % batch_size,len(frame_selection_list),transform_size[0],transform_size[1],channels))     # fix the last batch size\n",
    "            batch_labels = np.zeros((len(t) % batch_size,5))              # Similarly, for labels\n",
    "            for v_idx,folder in enumerate(t[(num_batches*batch_size):]):\n",
    "                #print(folder.split(';')[0])\n",
    "                imgs = os.listdir(source_path+\"/\"+folder.split(';')[0])\n",
    "                for idx, item in enumerate(img_idx):\n",
    "                    image = imread(source_path+'/'+folder.split(';')[0]+\"/\"+imgs[item]).astype(np.float64)\n",
    "                    image = image_processor(image,transform_size)\n",
    "\n",
    "                    if base_model:\n",
    "                        # This is when we are using a pre-learned CNN2D network\n",
    "                        image = process_input_func(image)\n",
    "                    else:\n",
    "                        # This is when we are building a Conv3D network\n",
    "                        image = image/255\n",
    "\n",
    "                    batch_data[v_idx,idx,:,:,0] = image[:,:,0]\n",
    "                    batch_data[v_idx,idx,:,:,1] = image[:,:,1]\n",
    "                    batch_data[v_idx,idx,:,:,0] = image[:,:,2]\n",
    "                batch_labels[v_idx,int(folder.split(\";\")[2])] = 1\n",
    "            if base_model:\n",
    "                s1 = batch_data.shape\n",
    "                n1 = base_model.predict(batch_data.reshape(s1[0]*s1[1],s1[2],s1[3],s1[4]))\n",
    "                s2 = n1.shape\n",
    "                batch_data = n1.reshape(s1[0],s1[1],s2[1],s2[2],s2[3])\n",
    "            yield batch_data,batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bd25cd0f01f9e269e0b94382525faed2815a7227",
    "colab_type": "text",
    "id": "80ys9uQWOoYZ"
   },
   "source": [
    "Recording *current_date-time* and fixing training data and validation data folder paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T10:03:24.621378Z",
     "start_time": "2018-12-24T10:03:24.554098Z"
    },
    "_uuid": "39075d8157407af445f4e66eade33cb1cf0b99a2",
    "colab": {},
    "colab_type": "code",
    "id": "7qG0kWgzOoYa"
   },
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = '../input/data/Project_data/train'\n",
    "val_path = '../input/data/Project_data/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "db716dc31b46e3cd1546dc0f580c83270c82f6c2",
    "colab_type": "text",
    "id": "PF4i-9NXOoYe"
   },
   "source": [
    "## Model\n",
    "Setting up base information for model building process.\n",
    "\n",
    "*IMPORTANT*\n",
    "We are using VGG19 pre-trained model for CONV2D modelling.\n",
    "\n",
    "If this code is CONV3D, then even though we are building the *base_model* and *preprocess_input_func* variables, but we will not use them further in the code.\n",
    "\n",
    "If this code is CONV2D+RNN type modelling, then we will use *base_model* and *preprocess_input_func* variables further in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T10:06:14.246527Z",
     "start_time": "2018-12-24T10:06:14.241521Z"
    },
    "_uuid": "164747b733d902a997d84f7d02a0402b29191359",
    "colab": {},
    "colab_type": "code",
    "id": "fiFuDsq6OoYe",
    "outputId": "47fb5c64-012f-4bf8-e3c4-a605d04815d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "train_data = train_doc\n",
    "val_data = val_doc\n",
    "transform_size = (90,90)\n",
    "batch_size = 16\n",
    "num_epochs = 50\n",
    "reduce_LR_patience = 5\n",
    "frame_selection_list = getframeselectionlist(choiceoflist=0)\n",
    "num_train_sequences = len(train_data)\n",
    "num_val_sequences = len(val_data)\n",
    "model_name = \"model_init_conv3d\"\n",
    "\n",
    "from keras.applications.vgg19 import VGG19 as base_conv2d_model\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "\n",
    "base_model = base_conv2d_model(weights=\"imagenet\",include_top=False)\n",
    "preprocess_input_func = preprocess_input\n",
    "\n",
    "os.environ.putenv(\"HDF5_USE_FILE_LOCKING\",\"FALSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "976d63b6fd893138ab78d94f849a8e7e9fc8e97d",
    "colab_type": "text",
    "id": "wSOSvHf6OoYi"
   },
   "source": [
    "#### Building Neural Network Model Architecture ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4244a03d9ba0e22baf37df04a0d2213aa15c01e3",
    "colab": {},
    "colab_type": "code",
    "id": "BL400NmSOoYj",
    "outputId": "437e2ec2-28fd-4c43-d8f9-29610814b885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ../input/data/Project_data/train ; batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape : (16, 30, 90, 90, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from keras.regularizers import l2\n",
    "\n",
    "input_sample = next(generator(train_path,\n",
    "                              train_data, \n",
    "                              batch_size=batch_size,\n",
    "                              transform_size=transform_size,\n",
    "                              frame_selection_list=frame_selection_list,\n",
    "                              process_input_func=None,\n",
    "                              base_model=None))\n",
    "print(\"Input batch shape : %s\" %(str(input_sample[0].shape)))\n",
    "model = Sequential()\n",
    "model.add(Conv3D(32,(3,3,3),padding=\"same\",input_shape = input_sample[0].shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv3D(32,(3,3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(3,3,3)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv3D(64,(3,3,3),padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv3D(64,(3,3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(3,3,3)))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,kernel_regularizer=l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(256,kernel_regularizer=l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(128,kernel_regularizer=l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(input_sample[1].shape[1]))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3d93a4b9645c2b7f03a0ffc80e90d8da2e0a5574",
    "colab_type": "text",
    "id": "tvdo9qDnOoYn"
   },
   "source": [
    "#### Setting up Neural Network configurations ####\n",
    "\n",
    "Optimizers\n",
    "loss function and metrics to be monitored.\n",
    "\n",
    "Watch out for model summary for verifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b517c918a846b31496088b9d11ec75c99ac8d5ed",
    "colab": {},
    "colab_type": "code",
    "id": "r80HO0oEOoYo",
    "outputId": "083eba6f-4857-4feb-e18e-716d7b12d780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 90, 90, 32)    2624      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 90, 90, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 90, 90, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 28, 88, 88, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 88, 88, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 88, 88, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 9, 29, 29, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 9, 29, 29, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 9, 29, 29, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 9, 29, 29, 64)     256       \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 7, 27, 27, 64)     110656    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 7, 27, 27, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 7, 27, 27, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 2, 9, 9, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               5308928   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 5,670,885\n",
      "Trainable params: 5,670,501\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "optimizer = optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "480846a185f095e6211018648a9ca869e426a770",
    "colab_type": "text",
    "id": "1wgLLYIoOoYt"
   },
   "source": [
    "#### Building up generator objects ####\n",
    "\n",
    "train_generator for training data\n",
    "\n",
    "val_generator for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T10:05:22.311781Z",
     "start_time": "2018-12-24T10:05:22.306781Z"
    },
    "_uuid": "dce5982a57adc031568e9296e5bec20baacccc33",
    "colab": {},
    "colab_type": "code",
    "id": "eKnXDrD5OoYv"
   },
   "outputs": [],
   "source": [
    "train_generator = generator(train_path,\n",
    "                            train_data, \n",
    "                            batch_size=batch_size,\n",
    "                            transform_size=transform_size,\n",
    "                            frame_selection_list=frame_selection_list,\n",
    "                            process_input_func=None,\n",
    "                            base_model=None)\n",
    "val_generator = generator(val_path,\n",
    "                          val_data, \n",
    "                          batch_size=batch_size,\n",
    "                          transform_size=transform_size,\n",
    "                          frame_selection_list=frame_selection_list,\n",
    "                          process_input_func=None,\n",
    "                          base_model=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7b8fb380f4b1e2c9206f84f9a1bb6d7b01bbdeeb",
    "colab_type": "text",
    "id": "2LTDivt_OoYx"
   },
   "source": [
    "#### Setting up extra parameter for Neural Network ####\n",
    "\n",
    "* ModelCheckPoint\n",
    "\n",
    "We build modelcheckpoint to save models after every epoch, so that we can refer to models to best model later on for final testing.\n",
    "* ReduceLROnPlateau\n",
    "\n",
    "If the **val_loss** value stops improving after **patience** number of epochs, we reduce the learning rate so as to take smaller steps down the gradient route for raeaching global minimum and avoid getting stuch at local minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T10:05:28.669954Z",
     "start_time": "2018-12-24T10:05:28.660949Z"
    },
    "_uuid": "35de3e1ba0f2c6291ccad46c3d4d41d074f32ebf",
    "colab": {},
    "colab_type": "code",
    "id": "lHPZdtsyOoYz",
    "outputId": "5538dd5a-714e-44e5-a350-76d90ba71ab3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_init_conv3d_2018-12-3002_59_55.602530/\n"
     ]
    }
   ],
   "source": [
    "model_name = model_name + \"_\" + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                       patience=reduce_LR_patience, min_lr=0.001,verbose=1)\n",
    "\n",
    "callbacks_list = [checkpoint, LR]\n",
    "#callbacks_list = [checkpoint]\n",
    "#callbacks_list = []\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5cfe4332858153c25fb98d5c29a09b97fa1d58ea",
    "colab_type": "text",
    "id": "Zcsgo_grOoY-"
   },
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T10:06:22.943538Z",
     "start_time": "2018-12-24T10:06:22.938534Z"
    },
    "_uuid": "d75fcb9f2e9175c9d5fce15698589d444def3c43",
    "colab": {},
    "colab_type": "code",
    "id": "Z8D0MyIaOoZB"
   },
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7fd4f0b7d78ea3bd7823a8d4f4e52ddd144582b8",
    "colab_type": "text",
    "id": "OIRx4gOsOoZG"
   },
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-24T09:33:39.785760Z",
     "start_time": "2018-12-24T09:33:24.008419Z"
    },
    "_uuid": "9651e405a2949affba9d4299d2b89f99c3fc6ef7",
    "colab": {},
    "colab_type": "code",
    "id": "RQfxTGJFOoZH",
    "outputId": "91fe9a10-3932-41a9-daf7-88a23306812e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Source path =  ../input/data/Project_data/val ; batch size = 16\n",
      "Source path =  ../input/data/Project_data/train ; batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/42 [===>..........................] - ETA: 3:06 - loss: 18.6366 - categorical_accuracy: 0.2708"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:54: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 161s 4s/step - loss: 16.7581 - categorical_accuracy: 0.3104 - val_loss: 16.2945 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00001: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00001-16.76581-0.31071-16.29452-0.38000.h5\n",
      "Epoch 2/50\n",
      "42/42 [==============================] - 117s 3s/step - loss: 15.9151 - categorical_accuracy: 0.4216 - val_loss: 15.7972 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00002: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00002-15.91120-0.42534-15.79718-0.38000.h5\n",
      "Epoch 3/50\n",
      "42/42 [==============================] - 119s 3s/step - loss: 15.4562 - categorical_accuracy: 0.4942 - val_loss: 15.2003 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00003: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00003-15.46074-0.49321-15.20034-0.55000.h5\n",
      "Epoch 4/50\n",
      "42/42 [==============================] - 120s 3s/step - loss: 15.0931 - categorical_accuracy: 0.5634 - val_loss: 15.0356 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00004: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00004-15.08851-0.56712-15.03559-0.53000.h5\n",
      "Epoch 5/50\n",
      "42/42 [==============================] - 118s 3s/step - loss: 14.8456 - categorical_accuracy: 0.5861 - val_loss: 14.7947 - val_categorical_accuracy: 0.5400\n",
      "\n",
      "Epoch 00005: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00005-14.83825-0.58824-14.79473-0.54000.h5\n",
      "Epoch 6/50\n",
      "42/42 [==============================] - 119s 3s/step - loss: 14.4249 - categorical_accuracy: 0.6729 - val_loss: 14.4428 - val_categorical_accuracy: 0.5700\n",
      "\n",
      "Epoch 00006: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00006-14.42644-0.67421-14.44281-0.57000.h5\n",
      "Epoch 7/50\n",
      "42/42 [==============================] - 116s 3s/step - loss: 14.1840 - categorical_accuracy: 0.6595 - val_loss: 14.2066 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00007: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00007-14.18415-0.66063-14.20662-0.60000.h5\n",
      "Epoch 8/50\n",
      "42/42 [==============================] - 119s 3s/step - loss: 13.8752 - categorical_accuracy: 0.7253 - val_loss: 13.8453 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00008: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00008-13.87963-0.72549-13.84527-0.68000.h5\n",
      "Epoch 9/50\n",
      "42/42 [==============================] - 118s 3s/step - loss: 13.5684 - categorical_accuracy: 0.7432 - val_loss: 14.3471 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00009: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00009-13.56906-0.74359-14.34708-0.50000.h5\n",
      "Epoch 10/50\n",
      "42/42 [==============================] - 118s 3s/step - loss: 13.2895 - categorical_accuracy: 0.7871 - val_loss: 13.7196 - val_categorical_accuracy: 0.6200\n",
      "\n",
      "Epoch 00010: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00010-13.29291-0.78431-13.71962-0.62000.h5\n",
      "Epoch 11/50\n",
      "42/42 [==============================] - 119s 3s/step - loss: 13.0075 - categorical_accuracy: 0.8281 - val_loss: 13.4971 - val_categorical_accuracy: 0.5900\n",
      "\n",
      "Epoch 00011: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00011-13.00756-0.82956-13.49707-0.59000.h5\n",
      "Epoch 12/50\n",
      "42/42 [==============================] - 120s 3s/step - loss: 12.7599 - categorical_accuracy: 0.8459 - val_loss: 13.0092 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00012: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00012-12.75826-0.84766-13.00923-0.72000.h5\n",
      "Epoch 13/50\n",
      "42/42 [==============================] - 120s 3s/step - loss: 12.4987 - categorical_accuracy: 0.8668 - val_loss: 12.9406 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00013: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00013-12.49224-0.86878-12.94061-0.65000.h5\n",
      "Epoch 14/50\n",
      "42/42 [==============================] - 119s 3s/step - loss: 12.3464 - categorical_accuracy: 0.8459 - val_loss: 12.9170 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00014: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00014-12.34322-0.84766-12.91696-0.61000.h5\n",
      "Epoch 15/50\n",
      "42/42 [==============================] - 121s 3s/step - loss: 12.0532 - categorical_accuracy: 0.8861 - val_loss: 13.0883 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00015: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00015-12.04951-0.88839-13.08833-0.50000.h5\n",
      "Epoch 16/50\n",
      "42/42 [==============================] - 118s 3s/step - loss: 11.8394 - categorical_accuracy: 0.9174 - val_loss: 12.5988 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00016: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00016-11.83615-0.92006-12.59882-0.60000.h5\n",
      "Epoch 17/50\n",
      "42/42 [==============================] - 118s 3s/step - loss: 11.6439 - categorical_accuracy: 0.8987 - val_loss: 12.7539 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00017: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00017-11.63830-0.90498-12.75390-0.46000.h5\n",
      "Epoch 18/50\n",
      "42/42 [==============================] - 117s 3s/step - loss: 11.4210 - categorical_accuracy: 0.9144 - val_loss: 12.6071 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00018: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00018-11.41306-0.91704-12.60715-0.60000.h5\n",
      "Epoch 19/50\n",
      "42/42 [==============================] - 115s 3s/step - loss: 11.2020 - categorical_accuracy: 0.9311 - val_loss: 11.9199 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00019: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00019-11.20121-0.93213-11.91990-0.69000.h5\n",
      "Epoch 20/50\n",
      "42/42 [==============================] - 117s 3s/step - loss: 11.0154 - categorical_accuracy: 0.9371 - val_loss: 12.1619 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00020: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00020-11.01157-0.93816-12.16192-0.61000.h5\n",
      "Epoch 21/50\n",
      "42/42 [==============================] - 116s 3s/step - loss: 10.8438 - categorical_accuracy: 0.9308 - val_loss: 12.5582 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00021: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00021-10.83612-0.93363-12.55822-0.50000.h5\n",
      "Epoch 22/50\n",
      "42/42 [==============================] - 119s 3s/step - loss: 10.6259 - categorical_accuracy: 0.9568 - val_loss: 11.3634 - val_categorical_accuracy: 0.6800\n",
      "\n",
      "Epoch 00022: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00022-10.62835-0.95626-11.36341-0.68000.h5\n",
      "Epoch 23/50\n",
      "42/42 [==============================] - 118s 3s/step - loss: 10.4492 - categorical_accuracy: 0.9486 - val_loss: 13.4315 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00023: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00023-10.44730-0.95173-13.43145-0.45000.h5\n",
      "Epoch 24/50\n",
      "42/42 [==============================] - 120s 3s/step - loss: 10.2834 - categorical_accuracy: 0.9520 - val_loss: 12.1176 - val_categorical_accuracy: 0.5600\n",
      "\n",
      "Epoch 00024: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00024-10.27835-0.95324-12.11763-0.56000.h5\n",
      "Epoch 25/50\n",
      "42/42 [==============================] - 119s 3s/step - loss: 10.1147 - categorical_accuracy: 0.9505 - val_loss: 11.0683 - val_categorical_accuracy: 0.6900\n",
      "\n",
      "Epoch 00025: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00025-10.11257-0.95173-11.06834-0.69000.h5\n",
      "Epoch 26/50\n",
      "42/42 [==============================] - 121s 3s/step - loss: 9.9197 - categorical_accuracy: 0.9684 - val_loss: 10.8680 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00026: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00026-9.91758-0.96983-10.86800-0.67000.h5\n",
      "Epoch 27/50\n",
      "42/42 [==============================] - 121s 3s/step - loss: 9.7255 - categorical_accuracy: 0.9806 - val_loss: 10.7186 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00027: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00027-9.72546-0.98039-10.71859-0.67000.h5\n",
      "Epoch 28/50\n",
      "42/42 [==============================] - 119s 3s/step - loss: 9.5664 - categorical_accuracy: 0.9821 - val_loss: 10.5033 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00028: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00028-9.56810-0.98190-10.50334-0.71000.h5\n",
      "Epoch 29/50\n",
      "42/42 [==============================] - 120s 3s/step - loss: 9.3903 - categorical_accuracy: 0.9851 - val_loss: 10.1899 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00029: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00029-9.39172-0.98492-10.18986-0.75000.h5\n",
      "Epoch 30/50\n",
      "42/42 [==============================] - 120s 3s/step - loss: 9.2666 - categorical_accuracy: 0.9743 - val_loss: 10.7828 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00030: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00030-9.26437-0.97587-10.78283-0.65000.h5\n",
      "Epoch 31/50\n",
      "42/42 [==============================] - 119s 3s/step - loss: 9.0965 - categorical_accuracy: 0.9866 - val_loss: 10.0215 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00031: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00031-9.09626-0.98643-10.02147-0.70000.h5\n",
      "Epoch 32/50\n",
      "42/42 [==============================] - 120s 3s/step - loss: 8.9345 - categorical_accuracy: 0.9896 - val_loss: 9.9958 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00032: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00032-8.93561-0.98944-9.99577-0.70000.h5\n",
      "Epoch 33/50\n",
      "42/42 [==============================] - 120s 3s/step - loss: 8.7994 - categorical_accuracy: 0.9873 - val_loss: 10.1253 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00033: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00033-8.78565-0.99095-10.12532-0.67000.h5\n",
      "Epoch 34/50\n",
      "42/42 [==============================] - 117s 3s/step - loss: 8.6762 - categorical_accuracy: 0.9806 - val_loss: 9.4424 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00034: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00034-8.67761-0.98039-9.44237-0.73000.h5\n",
      "Epoch 35/50\n",
      "42/42 [==============================] - 118s 3s/step - loss: 8.5011 - categorical_accuracy: 0.9907 - val_loss: 9.9202 - val_categorical_accuracy: 0.6600\n",
      "\n",
      "Epoch 00035: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00035-8.49498-0.99246-9.92020-0.66000.h5\n",
      "Epoch 36/50\n",
      "42/42 [==============================] - 120s 3s/step - loss: 8.3870 - categorical_accuracy: 0.9821 - val_loss: 10.2622 - val_categorical_accuracy: 0.6100\n",
      "\n",
      "Epoch 00036: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00036-8.38666-0.98190-10.26223-0.61000.h5\n",
      "Epoch 37/50\n",
      "42/42 [==============================] - 121s 3s/step - loss: 8.2218 - categorical_accuracy: 0.9911 - val_loss: 9.2978 - val_categorical_accuracy: 0.6700\n",
      "\n",
      "Epoch 00037: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00037-8.22262-0.99095-9.29780-0.67000.h5\n",
      "Epoch 38/50\n",
      "42/42 [==============================] - 120s 3s/step - loss: 8.0840 - categorical_accuracy: 0.9926 - val_loss: 9.0577 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00038: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00038-8.08450-0.99246-9.05771-0.70000.h5\n",
      "Epoch 39/50\n",
      "42/42 [==============================] - 119s 3s/step - loss: 7.9459 - categorical_accuracy: 0.9985 - val_loss: 8.9886 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00039: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00039-7.94682-0.99849-8.98857-0.70000.h5\n",
      "Epoch 40/50\n",
      "42/42 [==============================] - 118s 3s/step - loss: 7.8195 - categorical_accuracy: 0.9866 - val_loss: 8.8998 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00040: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00040-7.81966-0.98643-8.89976-0.71000.h5\n",
      "Epoch 41/50\n",
      "42/42 [==============================] - 121s 3s/step - loss: 7.6903 - categorical_accuracy: 0.9940 - val_loss: 8.7325 - val_categorical_accuracy: 0.7400\n",
      "\n",
      "Epoch 00041: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00041-7.69051-0.99397-8.73251-0.74000.h5\n",
      "Epoch 42/50\n",
      "42/42 [==============================] - 119s 3s/step - loss: 7.5516 - categorical_accuracy: 1.0000 - val_loss: 8.4559 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00042: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00042-7.55259-1.00000-8.45595-0.73000.h5\n",
      "Epoch 43/50\n",
      "42/42 [==============================] - 120s 3s/step - loss: 7.4309 - categorical_accuracy: 0.9955 - val_loss: 8.3081 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00043: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00043-7.43115-0.99548-8.30807-0.75000.h5\n",
      "Epoch 44/50\n",
      "42/42 [==============================] - 119s 3s/step - loss: 7.3061 - categorical_accuracy: 0.9955 - val_loss: 8.3706 - val_categorical_accuracy: 0.7300\n",
      "\n",
      "Epoch 00044: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00044-7.30657-0.99548-8.37056-0.73000.h5\n",
      "Epoch 45/50\n",
      "42/42 [==============================] - 120s 3s/step - loss: 7.1922 - categorical_accuracy: 0.9955 - val_loss: 8.1594 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00045: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00045-7.19317-0.99548-8.15937-0.70000.h5\n",
      "Epoch 46/50\n",
      "42/42 [==============================] - 120s 3s/step - loss: 7.0666 - categorical_accuracy: 0.9970 - val_loss: 8.2790 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00046: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00046-7.06730-0.99698-8.27896-0.70000.h5\n",
      "Epoch 47/50\n",
      "42/42 [==============================] - 120s 3s/step - loss: 6.9502 - categorical_accuracy: 0.9970 - val_loss: 7.8163 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00047: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00047-6.95111-0.99698-7.81628-0.75000.h5\n",
      "Epoch 48/50\n",
      "42/42 [==============================] - 120s 3s/step - loss: 6.8346 - categorical_accuracy: 0.9970 - val_loss: 7.7841 - val_categorical_accuracy: 0.7200\n",
      "\n",
      "Epoch 00048: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00048-6.83539-0.99698-7.78407-0.72000.h5\n",
      "Epoch 49/50\n",
      "42/42 [==============================] - 119s 3s/step - loss: 6.7241 - categorical_accuracy: 1.0000 - val_loss: 7.6960 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00049: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00049-6.72467-1.00000-7.69603-0.71000.h5\n",
      "Epoch 50/50\n",
      "42/42 [==============================] - 119s 3s/step - loss: 6.6202 - categorical_accuracy: 0.9955 - val_loss: 7.9949 - val_categorical_accuracy: 0.6300\n",
      "\n",
      "Epoch 00050: saving model to model_init_conv3d_2018-12-3002_59_55.602530/model-00050-6.61957-0.99548-7.99490-0.63000.h5\n"
     ]
    }
   ],
   "source": [
    "conv3d_model = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                              callbacks=callbacks_list, validation_data=val_generator, \n",
    "                              validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "db43a64d2384f862d0eb3050827f9fe9b5954490",
    "colab_type": "text",
    "id": "k8BjqdTBOoZK"
   },
   "source": [
    "#### Building graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fbfecf8ed88165afb8a62d6a5a6c5521bb24050d",
    "colab": {},
    "colab_type": "code",
    "id": "jo5w78mLOoZK",
    "outputId": "043e6bc1-c693-4dab-c17c-ffc225a6839f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(conv3d_model.history[\"categorical_accuracy\"])\n",
    "plt.plot(conv3d_model.history[\"val_categorical_accuracy\"])\n",
    "plt.xlabel(\"EPOCHS\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.ylim(0.0,1.0)\n",
    "plt.title(\"Model Performance (Conv3D)\")\n",
    "plt.legend([\"train\",\"test\"],loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ccfe87a75801bc2fbcbb098dda901cd86981decc",
    "colab": {},
    "colab_type": "code",
    "id": "gBfsqud3OoZO",
    "outputId": "04f5a30a-1c16-45c7-d4a0-d7dcd1e009d0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(conv3d_model.history[\"loss\"])\n",
    "plt.plot(conv3d_model.history[\"val_loss\"])\n",
    "plt.xlabel(\"EPOCHS\")\n",
    "plt.ylabel(\"LOSS\")\n",
    "#plt.ylim(0.0,3.0)\n",
    "plt.title(\"Conv3D Model (LOSS)\")\n",
    "plt.legend([\"Train\",\"Testing\"],loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f93305c6acd878497f23ff3248a3a476f2c992a9",
    "colab_type": "text",
    "id": "YOKtgiXvOoZR"
   },
   "source": [
    "#### Checking the EPOCH index where maximum validation accuracy was achieved ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0a351c51b5fbd95219c9f3931ed05979244b8c6",
    "colab": {},
    "colab_type": "code",
    "id": "FFWmhBHhOoZT",
    "outputId": "e7cd814b-fca1-45d8-92ac-dec0a02e8be4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Validation Accuracy = 0.750000 achieved at epoch iteration = 29\n"
     ]
    }
   ],
   "source": [
    "print(\"Maximum Validation Accuracy = %f achieved at epoch iteration = %d\" %(np.array(conv3d_model.history[\"val_categorical_accuracy\"]).max(),np.array(conv3d_model.history[\"val_categorical_accuracy\"]).argmax() + 1))\n",
    "sel_model_idx = np.array(conv3d_model.history[\"val_categorical_accuracy\"]).argmax() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eaa234895dc26c59456f0b4547bdc8c1cce7c225",
    "colab_type": "text",
    "id": "Sg0NaK11OoZX"
   },
   "source": [
    "#### Selecting h5 file for loading model ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c8bb05994e82756d97707607328324a6fefeadf7",
    "colab": {},
    "colab_type": "code",
    "id": "773SSpkYOoZX",
    "outputId": "2a45940b-a55c-4098-d2ed-6716ffe5ee2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model name : model_init_conv3d_2018-12-3002_59_55.602530/model-00029-9.39172-0.98492-10.18986-0.75000.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "search_string = \"model-0*\" + str(sel_model_idx) + \"-[a-z0-9\\-\\.]*\"\n",
    "selected_model_name = model_name + list(filter(lambda x: re.search(search_string,x),os.listdir(model_name)))[0]\n",
    "print(\"Selected model name : %s\" %(selected_model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "beb2a9e26a0ec583942d9c6608c87ae496a162ba",
    "colab_type": "text",
    "id": "HYc_Z-t0OoZe"
   },
   "source": [
    "#### Loading model weights from h5 file ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c5a7e6864c083885097eab58790c632c81a30369",
    "colab": {},
    "colab_type": "code",
    "id": "s79A9PB0OoZg"
   },
   "outputs": [],
   "source": [
    "from keras.models import clone_model\n",
    "selected_model = clone_model(model)\n",
    "selected_model.load_weights(selected_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "886a1d6fc7893faaa031d661c3374a898b08e32b",
    "colab_type": "text",
    "id": "EVMQrlvAOoZl"
   },
   "source": [
    "#### Performing prediction on validation data ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "31df620b2298c7fa018fb8d00b4c08e70686b135",
    "colab": {},
    "colab_type": "code",
    "id": "fYAQSx-EOoZp",
    "outputId": "755c44b5-627c-4fac-d8b8-9a9f04c83552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  ../input/data/Project_data/val ; batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/opt/conda/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 51ms/step\n",
      "16/16 [==============================] - 1s 37ms/step\n",
      "16/16 [==============================] - 1s 34ms/step\n",
      "16/16 [==============================] - 1s 35ms/step\n",
      "16/16 [==============================] - 1s 34ms/step\n",
      "16/16 [==============================] - 1s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:54: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 32ms/step\n"
     ]
    }
   ],
   "source": [
    "testing_val_generator = generator(val_path,\n",
    "                          val_data, \n",
    "                          batch_size=batch_size,\n",
    "                          transform_size=transform_size,\n",
    "                          frame_selection_list=frame_selection_list,\n",
    "                          process_input_func=None,\n",
    "                          base_model=None)\n",
    "result = None\n",
    "for x in range(validation_steps):\n",
    "    x_val,y_val = next(testing_val_generator)\n",
    "    p_val = selected_model.predict(x_val,batch_size=batch_size,verbose=1)\n",
    "    if x == 0:\n",
    "        result = np.vstack((y_val.argmax(axis=1),p_val.argmax(axis=1)))\n",
    "    else:\n",
    "        result = np.hstack((result,np.vstack((y_val.argmax(axis=1),p_val.argmax(axis=1)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cf5c2d1a7aea099059e723f2fac9961604b9b41a",
    "colab_type": "text",
    "id": "ktaazwc9OoZv"
   },
   "source": [
    "#### Consolidating Results ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "846ab6db846b74c8553fdd638eed853e8c9a9c9b",
    "colab": {},
    "colab_type": "code",
    "id": "ZSZBaUtGOoZx"
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(np.transpose(result),columns=[\"Actual\",\"Predicted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ee73ccf892b823177b634e106d2ae391807739b9",
    "colab": {},
    "colab_type": "code",
    "id": "ms7Zl1HvOoZ5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-30T13:53:10.760345Z",
     "start_time": "2018-12-30T13:53:10.742333Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "QCbaGGqUOoaC",
    "outputId": "3da5e47c-a46c-42df-e6c4-91ff9d00eeaa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Left</th>\n",
       "      <th>Predicted_Right</th>\n",
       "      <th>Predicted_Stop</th>\n",
       "      <th>Predicted_Down</th>\n",
       "      <th>Predicted_Up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual_Left</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual_Right</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual_Stop</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual_Down</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual_Up</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Predicted_Left  Predicted_Right  Predicted_Stop  Predicted_Down  \\\n",
       "Actual_Left               10                6               1               1   \n",
       "Actual_Right               0               23               0               0   \n",
       "Actual_Stop                3                2              12               3   \n",
       "Actual_Down                0                0               0              19   \n",
       "Actual_Up                  1                0               2               2   \n",
       "\n",
       "              Predicted_Up  \n",
       "Actual_Left              0  \n",
       "Actual_Right             0  \n",
       "Actual_Stop              2  \n",
       "Actual_Down              2  \n",
       "Actual_Up               11  "
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_np = confusion_matrix(result.Actual,result.Predicted,labels=range(0,5))\n",
    "cf_df = pd.DataFrame(cf_np,columns=[\"Predicted_\" + str(x) for x in [\"Left\",\"Right\",\"Stop\",\"Down\",\"Up\"]],index=[\"Actual_\" + str(x) for x in [\"Left\",\"Right\",\"Stop\",\"Down\",\"Up\"]])\n",
    "cf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3c34c540cd44296a54fcaa3e327752b76d4b9bb8",
    "colab": {},
    "colab_type": "code",
    "id": "aOxkOmymOoaH",
    "outputId": "c8684de4-e40e-41f1-820a-1ae5848f1d53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cummalative Accuracy Score : 0.750000\n",
      "Cummalative Categorical Accuracy : 0.760000\n"
     ]
    }
   ],
   "source": [
    "print(\"Cummalative Accuracy Score : %f\" %(accuracy_score(result.Actual,result.Predicted)))\n",
    "print(\"Cummalative Categorical Accuracy : %f\" %(0.7600))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "CNN3D_final_version.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
